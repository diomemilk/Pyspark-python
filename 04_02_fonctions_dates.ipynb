{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FR_2843_04_02_fonctions_dates.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrENSXwjcdMT",
        "outputId": "d50a32a1-80ea-47e8-cc06-5475067e35d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-2.3.1/spark-2.3.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.3.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.or\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Waiting for headers] [3 InRelease 14.2 kB/88.7 kB 16%] [Connected to cloud.\r0% [1 InRelease gpgv 15.9 kB] [Waiting for headers] [3 InRelease 28.7 kB/88.7 k\r                                                                               \rGet:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\r0% [1 InRelease gpgv 15.9 kB] [4 InRelease 14.2 kB/88.7 kB 16%] [3 InRelease 37\r                                                                               \rHit:5 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 15.9 kB] [4 InRelease 15.6 kB/88.7 kB 18%] [3 InRelease 43\r0% [1 InRelease gpgv 15.9 kB] [4 InRelease 47.5 kB/88.7 kB 54%] [Waiting for he\r                                                                               \rHit:6 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Ign:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Fetched 252 kB in 2s (163 kB/s)\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWx7lbjjciTy",
        "outputId": "b1d8ad97-cc58-491d-a9bf-ae4f9e538812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.3.1-bin-hadoop2.7\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark import SparkContext\n",
        "sc = SparkContext.getOrCreate()\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate() \n",
        "spark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://62130eefe081:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v2.3.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f92db4d1a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu67mbm-upHB",
        "outputId": "28786c66-ceef-4beb-fc40-c81ee1ade168",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df1 = spark.createDataFrame(((\"2021-01-23\",1),(\"2021-06-24\",2),(\"2021-09-20\",3)),(\"date\",\"nombre_de_mois\"))\n",
        "df1.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+--------------+\n",
            "|      date|nombre_de_mois|\n",
            "+----------+--------------+\n",
            "|2019-01-23|             1|\n",
            "|2019-06-24|             2|\n",
            "|2019-09-20|             3|\n",
            "+----------+--------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOLoBrB90zxk",
        "outputId": "0aae159a-c904-4397-e45d-a5ec0350a384",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pyspark.sql.functions as F\n",
        "df1.withColumn(\"nouvelle_date\",F.add_months(col(\"date\"), df1.first()[1])).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+--------------+-------------+\n",
            "|      date|nombre_de_mois|nouvelle_date|\n",
            "+----------+--------------+-------------+\n",
            "|2019-01-23|             1|   2019-02-23|\n",
            "|2019-06-24|             2|   2019-07-24|\n",
            "|2019-09-20|             3|   2019-10-20|\n",
            "+----------+--------------+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jteozBGwzOAR",
        "outputId": "62d0bda1-5ea5-4f91-d657-b26793ad815d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df2 = spark.createDataFrame([(\"2021_01_11\",)],[\"date\"])\n",
        "df2.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+\n",
            "|      date|\n",
            "+----------+\n",
            "|2021_01_11|\n",
            "+----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l_7wX00548d",
        "outputId": "28a4b2bb-7508-4158-a900-c895978cd984",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df2.select(F.date_format('date', 'MM-dd-yyy').alias('Format date')).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+\n",
            "|Format date|\n",
            "+-----------+\n",
            "|       null|\n",
            "+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRi7_126KZf8",
        "outputId": "136e74c5-e8cb-4c6a-8bf2-9c8c0627c00d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df2.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- date: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff4iSE4pKtUp",
        "outputId": "6c5ab91b-5bf9-4e07-bc3b-813fac441b44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from pyspark.sql.functions import to_date\n",
        " \n",
        "df3 = df2.withColumn('date',to_date(df2.date, 'yyyy_MM_dd'))\n",
        "df3.printSchema()\n",
        "df3.select(\"date\").dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- date: date (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('date', 'date')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCbdFsBQONUm",
        "outputId": "dfef77ae-4dfd-4c64-e4d0-b43c53b9e0e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df3.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+\n",
            "|      date|\n",
            "+----------+\n",
            "|2021-01-11|\n",
            "+----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBGtbye5Eza1",
        "outputId": "ee03f4d5-5a0c-4dd1-c570-92ec06a199ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df3.select(F.date_format('date', 'MM-dd-yyy').alias('Format date')).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+\n",
            "|Format date|\n",
            "+-----------+\n",
            "| 01-11-2021|\n",
            "+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGaMbMMLIoT6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}